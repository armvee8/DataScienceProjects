---
title: "Exploratory Data Analysis and Modeling"
author: "Veronica Weiss"
date: "4/6/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(caret)
library(OneR)
library(mlbench)
library(e1071)
library(rpart)
```

#Exploratory Data Analysis 

```{r}
phish <- read.csv('/students/home/vweiss/Desktop/TrainingDataset.csv')
```

We begin Exploratory Data Analysis by seeing the correlations between the variables.
#Show half of the plot
#Box plots to show the different levels of 0 and 1 
#Tapply (quantitative, categorical, function)
```{r}
cor.p <- cor(phish)
cor.p[]
cor.p
corrplot(cor.p, type = "upper", tl.pos = "td",
         method = "circle", tl.cex = 0.5, tl.col = 'black',
         order = "hclust", diag = FALSE, main = "Correlation Plot")
```

It appears that a relationship between domain_registration length and the following variables: URL_Length, Result, Request_URL. Based on the correlation, Domain_registration_length has the strongest relationship with Request_URL. 

It appears that Redirect has a relationship between DNSRecord, Having_IP_Address, Abnormal_URL, HTTPS_token, Shortnining_Service, and double_slash_redirecting. The strongest relationship for Redirect seems to be double_slash_redirecting in the negative direction, but the other 4 variables previously listed are also somewhat strongly negatively related to Redirect. 

It appears that links_pointing_to_page has a strong negative relationship with having_IP_address and DNSRecord.

The following are strong positive correlations in this dataset:
RightClick and iFrame
RightClick and Port
RightClick and Submitting_to_Email
RightClick and on_mouseover
RightClick and Favicon
RightClick and Pop up Window
SSLfinal_State and Result
URL_of_Anchor and Result 
URL_Length and SFH

The following are strong negative correlations in this dataset:
Request_URL and Domain_registration_length
Abnormal_URL and Redirect
HTTPs_Token and Redirect
Shortning_Service and Redirect
double_slash_redirecting and Redirect


Variables with one or more positive notable correlations are: Shortning_Service, HTTPS_Token, Abnormal_URL, DNSRecord, Favicon, on_mouseover, Submitting_to_email, port, iframe, RightClick,SSLfinal_State, URL_of_Anchor, Prefix_Suffix, URL_Length

*~~*SO LET'S VISUALIZE**~~*
  colors = c("#CD1658", "#4000E6")


Graphs to make:
Waffle chart 

```{r}
ggplot(phish, aes(x=Result, fill = '#CD1658')) +
  geom_bar() + theme_minimal() + legend()
```

```{r}
barplot(resultsPhish)
legend(legend = c("Phishing, Legitimate"))
```

```{r}
ggplot(phish, aes(x = Result, color = Result)) + geom_histogram(fill = "#3ECBC4") + ggtitle("Histogram of Result") + scale_x_continuous(breaks = seq(-1, 1, by = 1)) 

```


```{r}
resultsLegitimate <- phish$Result == 1
resultsPhish <- phish$Result == 0
```

```{r}
with(phish, table(Result, SSLfinal_State))

```

The dataset has identified more websites to be phishing than not phishing. 

Bar plot 
Bar plot with a grouping 
Box plot  (used with arrange)
Boxen plot 

#Splitting the Data into Train and Test Sets

60% of the data will be in the training set. 

```{r}
trainSet <- createDataPartition(phish$Result, p=.6)[[1]]
phish.train <- phish[trainSet,]
phish.test <- phish[-trainSet,]
```

#Modeling
MODELS TO TRY:
XGboost
Light GBM 

We can use Naive Bayes and RIPPER (Repeated Incremental Pruning to Produce Error Reduction). Each model will have a section for feature extraction, modeling, and evaluation. Then after we preform all those steps, we will enter the deployment phase by avowing which model is the most optimal.


##Modeling for Naive Bayes

```{r}
phish.train$Result <- as.factor(phish.train$Result)
phish.test$Result <- as.factor(phish.test$Result)
```

```{r}
phish.nb.model <- naiveBayes(Result ~ ., data = phish.train)
phish.nb.pred <- predict(phish.nb.model, phish.test)
  
eval_model(phish.nb.pred, phish.test)
```

Out of the box Naive Bayes: 71% accuracy.

##Feature Extraction for Naive Bayes
```{r}
control <- rfeControl(functions = nbFuncs)
rfe <- rfe(phish.train[,1:30], as.factor(phish.train[,31]), sizes = c(1:30), rfeControl = control)
```

```{r}
rfe
```

Recursive feature extraction with 25 repetition of bootstraps reports that the top 5 variables are SSLfinal_State, URL_of_Anchor, web_traffic, having_Sub_Domain, and Links_in_tags. 

##Add in the part of R from the Linux machine on here

```{r}
phish.nb.model <- naiveBayes(Result ~ SSLfinal_State+URL_of_Anchor+web_traffic+having_Sub_Domain+Links_in_tags, data = phish.train)
phish.nb.pred <- predict(phish.nb.model, phish.test)
  
eval_model(phish.nb.pred, phish.test)

```

##Modeling for Ripper - use RIPPER to create a rule set

```{r}
phish.ripper <- JRip(Result ~ ., data = phish.train)
print(phish.ripper)
```

```{r}
summary(phish.ripper)
```

96% Accuracy? Has to be overfitting. So let's evaluate on the testing data.

```{r}
phish.ripper.test <- JRip(Result ~ ., data = phish.test)
summary(phish.ripper.test)
```

RIPPER on the testing set gives a very similar accuracy of 95%. 

##Modeling using a C4.5 Decision Tree

```{r}
phish.c45tree <- J48(Result ~ ., data = phish.train)
summary(phish.c45tree)
```

###Evaluation for C4.5 Decision Tree

```{r}
phish.c45tree.eval <- J48(Result ~ ., data = phish.test)
summary(phish.c45tree.eval)
```

##Modeling with Gradiant Boosting Algorithms

XGboost is a Kaggle favorite and kind of the cool kid on the block. 

XGboost can only deal with numeric data, not categorical. So we'll have to encode the categorical data with one-hot encoding. A sparse matrix function can be used to preform one-hot encoding.
We should change -1 and 1 in the Result column to 0 and 1. So where we have -1, we should have 0. 

```{r}
phish.train$Result <- gsub(-1, 0, phish.train$Result)
```

```{r}
train.matrix <- sparse.model.matrix(Result~.-1,phish.train)
#test.matrix <- sparse.model.matrix(phish.test)
```

```{r}
output_vector = as.numeric(phish.train$Result)
```

We also need to put the test data into a sparse matrix.

```{r}
sparse_matrix_test <- sparse.model.matrix(Result ~ .-1, data = phish.test)
phish.test$Result <- gsub(-1, 0, phish.test$Result)
output_vector_test = as.numeric(phish.test$Result)
```

Now we build the xgboost model.

```{r}
phish.xgboost <- xgboost(data = train.matrix, label = output_vector, eta = 1, nrounds = 10, nthread = 2, objective = "binary:logistic")
```

##Modeling with Neural Networks

Create the neural network for five variables.

#CODE FOR NEURALNET

Step 1: 
Preprocess the data. Result should have 0 and 1 instead of -1 and 1. 
```{r}
library(neuralnet)
phish.train.NN <- phish.train
phish.train.NN$Result <- gsub(-1, 0, phish.train$Result)
```

Preprocessing above for the testing set.
```{r}
phish.test.NN <- phish.test
phish.test.NN$Result <- gsub(-1, 0, phish.test$Result)
```

```{r}
library(dplyr)
colsOfInterest<- phish.train.NN %>% select(SSLfinal_State, URL_of_Anchor, web_traffic, having_Sub_Domain, Links_in_tags, Result)
```

```{r}
colsOfInterest <- names(colsOfInterest)
```

```{r}
#f <- as.formula("Result ~ .")
f <- as.formula(paste("Result ~ ", 
      paste(names(phish.train.NN[!names(phish.train.NN) %in% 'Result']), 
            collapse = " + "), sep=""))

```

```{r}
phish.train.NN$Result<- as.numeric(phish.train.NN$Result)
```

```{r}
phish.test.NN$Result <- as.numeric(phish.test.NN$Result)
```

```{r}
nn <- neuralnet(f, data=phish.train.NN, hidden = c(3,4), algorithm = 'backprop', learningrate = 0.02, linear.output = FALSE)
```

Print the neural network
```{r}
plot(nn)
```


##EVALUATE NEURAL NETWORK

PREPARING THE TESTING SET FOR NN: 
We need to replace the -1s with 0s. 


Need to reproduce above for the testing set.

Now we need to create predictions off of the test set.

```{r}
testing.for.Predicts <- (phish.test.NN[,-31])
```

```{r}
predicted.nn <- neuralnet::compute(nn, testing.for.Predicts)
```

Let's look at the results.

```{r}
results <- data.frame(actual = phish.test.NN$Result, prediction = predicted.nn$net.result)
```

```{r}
results
```

Make a confusion matrix to evaluate.

```{r}
roundedresults <- sapply(results, round, digits = 0)
roundedresultsdf <- data.frame(roundedresults)
attach(roundedresultsdf)
table(actual,prediction)
```

```{r}
confusionMatrixNN<- confusionMatrix(round(predicted.nn$net.result), phish.test.NN$Result)
print(confusionMatrixNN)
```

Print out the net.result 
```{r}
print(head(predicted.nn5vars$net.result))
```

Now we round probabilities to predict yes or no.

```{r}
predicted.nn5vars$net.result <- sapply(predicted.nn5vars$net.result,round,digits=0)
```

```{r}
table(phish.test.NN$Result, predicted.nn5vars$net.result)
```

```{r}
nn_allVars <- neuralnet(Result ~ ., data=phish.train, hidden = c(7370), linear.output=FALSE)
```

```{r}
phish.train.matrix <- as.matrix(phish.train)
phish.test.matrix <- as.matrix(phish.test)
```

#CODE FOR KERAS 

```{r}
phish.NN <- keras_model_sequential() 
#Units should be 2/3 of the input layer....7370??????? Lol What Am I Doing
phish.NN %>% 
                layer_dense(units = 7370, activation = 'relu') %>%
                layer_dropout(rate = 0.4) %>%
                layer_dense(units = 7370, activation = 'relu') %>%
                layer_dropout(rate = 0.4) %>%
                layer_dense(units = 1, activation = 'softmax')
```


```{r}
phish.NN %>% 
  compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = c('accuracy'))
```


```{r}
neuralnetwork <- phish.NN %>% fit(
  phish.train.matrix, epochs = 30, batch_size = 138, validation_split = 0.2
)
```

```{r}
neuralnetwork %>% evaluate(phish.train.matrix, phish.test.matrix)
```
